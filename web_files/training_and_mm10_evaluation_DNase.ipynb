{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-----import packages-----#\n",
    "\n",
    "#common python packages\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import wget\n",
    "import math\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "#biological packages\n",
    "import pybedtools\n",
    "from pybedtools import featurefuncs\n",
    "import pyBigWig\n",
    "\n",
    "#machine learning packages\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten, GlobalAveragePooling2D, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.utils import Sequence, plot_model\n",
    "from keras.constraints import unit_norm\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, Callback, TensorBoard, ReduceLROnPlateau\n",
    "import keras_metrics as km\n",
    "from keras.models import load_model\n",
    "\n",
    "from models.v8 import create_model\n",
    "from models.custom_metrics import auroc, auprc, recall_m, precision_m, f1_m\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#notify the OS about GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files found!\n"
     ]
    }
   ],
   "source": [
    "#parsing command line arguments\n",
    "# -----parsing command line arguments-----#\n",
    "parser = argparse.ArgumentParser(description='Training CNN model to predict STARR-seq enhancers based on chromatin accessbility and histone marks')\n",
    "parser.add_argument('-c', '--cell_types', type=str, help='comma separated string of cell_types')\n",
    "parser.add_argument('-i', '--in_dir', type=str, help='directory containing 01_data_encoding intermediate tsv files')\n",
    "\n",
    "#simulate command line input\n",
    "cmdline_str='-c ' + \" HepG2,K562 \" + \\\n",
    "    ' -i ' + \"./encode/dev/encoded_2overlap/DNase/\"\n",
    "\n",
    "seq_names = [\"H3K27ac\", \"H3K4me3\", \"DNase\", \"H3K9ac\", \"H3K4me1\"]\n",
    "\n",
    "#check if the files are there\n",
    "args = parser.parse_args(cmdline_str.split())\n",
    "args.cell_types = args.cell_types.split(\",\")\n",
    "for cell in args.cell_types:\n",
    "    for seq in seq_names:\n",
    "        pos_file = args.in_dir + cell + \".\" + seq + \".pos.tsv\"\n",
    "        if not os.path.exists(pos_file):\n",
    "            print(pos_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "        neg_file = args.in_dir + cell + \".\" + seq + \".neg.tsv\"\n",
    "        if not os.path.exists(neg_file):\n",
    "            print(neg_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "print(\"all files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HepG2\n",
      "-H3K27ac\n",
      "-H3K4me3\n"
     ]
    }
   ],
   "source": [
    "def get_data(cell_types, in_dir, seq_names):\n",
    "\n",
    "    first_cell = True\n",
    "    for cell in cell_types:\n",
    "        print(cell)\n",
    "\n",
    "        pos = []\n",
    "        neg = []\n",
    "        first_seq = True\n",
    "        for seq in seq_names:\n",
    "            print(\"-\"+seq)\n",
    "\n",
    "            pos_name = in_dir+cell+\".\"+seq+\".pos.tsv\"\n",
    "            pos_mat = np.loadtxt(pos_name, delimiter='\\t')\n",
    "\n",
    "            neg_name = in_dir+cell+\".\"+seq+\".neg.tsv\"\n",
    "            neg_mat = np.loadtxt(neg_name, delimiter='\\t')\n",
    "\n",
    "            if first_seq:\n",
    "                for i in pos_mat:\n",
    "                    pos.append(np.array([i]))\n",
    "                for i in neg_mat:\n",
    "                    neg.append(np.array([i]))\n",
    "                first_seq = False\n",
    "            else:\n",
    "                for i in range(len(pos)):\n",
    "                    pos[i] = np.vstack((pos[i], pos_mat[i,]))\n",
    "                for i in range(len(neg)):\n",
    "                    neg[i] = np.vstack((neg[i], neg_mat[i,]))\n",
    "\n",
    "        if first_cell == True:\n",
    "            X_pos = np.array(pos)\n",
    "            X_neg = np.array(neg)\n",
    "            first_cell = False\n",
    "        else:\n",
    "            X_pos = np.vstack((X_pos, pos))\n",
    "            X_neg = np.vstack((X_neg, neg))\n",
    "\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    y = np.array([1 for i in range(X_pos.shape[0])] + [0 for i in range(X_neg.shape[0])]).reshape(-1,1)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return X, y\n",
    "  \n",
    "X, y = get_data(args.cell_types, args.in_dir, seq_names)\n",
    "with open(args.in_dir + \"hg38_signals.pickle\", 'wb') as f:\n",
    "    pickle.dump((X,y), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.in_dir + \"hg38_signals.pickle\", 'rb') as f:\n",
    "    X, Y = pickle.load(f)\n",
    "window_size = int(X.shape[2] * 10)\n",
    "#X[:, [0, 2], :] = X[:, [2, 0], :]\n",
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "x_train = np.expand_dims(X, axis=4)\n",
    "y_train = Y\n",
    "\n",
    "#calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(y_train),\n",
    "                                                  y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the model\n",
    "model = create_model(width=int(window_size/10))\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "adam = Adam(lr=5e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=9e-5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, \n",
    "    metrics=['accuracy', auroc, auprc, f1_m, recall_m, precision_m])\n",
    "\n",
    "if os.path.exists('./saved_models/DNase_hg38.v8.h5'):\n",
    "    model.load_weights('./saved_models/DNase_hg38.v8.h5')\n",
    "else:\n",
    "    #train the model\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=100,\n",
    "                        validation_split=0.1,\n",
    "                        shuffle=True,\n",
    "                        class_weight=class_weights,\n",
    "                        callbacks=[es]) \n",
    "\n",
    "    model.save_weights('./saved_models/DNase_hg38.v8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n"
     ]
    }
   ],
   "source": [
    "print(\"done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./mm10/mm10_all_signals.pickle\", 'rb') as f:\n",
    "    X,Y = pickle.load(f)\n",
    "samples = [\"forebrain\", \"heart\", \"hindbrain\", \"limb\", \"midbrain\", \"neural tube\"]\n",
    "for i in range(len(samples)):\n",
    "    X[i][:, [0, 2], :] = X[i][:, [2, 0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forebrain validation accuracy is: 0.6750924784217016\n",
      "heart validation accuracy is: 0.7034525277435265\n",
      "hindbrain validation accuracy is: 0.6448828606658447\n",
      "limb validation accuracy is: 0.6596794081381011\n",
      "midbrain validation accuracy is: 0.6760172626387176\n",
      "neural tube validation accuracy is: 0.6384093711467325\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "accuracy_list = []\n",
    "for i in range(len(samples)):\n",
    "    y_pred = model.predict(X[i]).ravel()\n",
    "    y_pred_list.append(y_pred)\n",
    "\n",
    "    accuracy_s = sklearn.metrics.accuracy_score(Y[i], np.rint(y_pred))\n",
    "    print(samples[i], \"validation accuracy is:\", accuracy_s)\n",
    "    accuracy_list.append(accuracy_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC in test set\n",
    "ax = plt.figure(figsize=(5, 5))\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "tpr_list = []\n",
    "auroc_list = []\n",
    "for i in range(len(Y)):\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(Y[i], y_pred_list[i])\n",
    "    auroc_list.append(sklearn.metrics.roc_auc_score(Y[i], y_pred_list[i]))\n",
    "    plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "    tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tpr_list.append(tpr)\n",
    "\n",
    "print(len(tpr_list), len(tpr_list[0]), len(tpr_list[1]))\n",
    "tpr_list = np.array(tpr_list)\n",
    "mean_tpr = np.mean(np.array(tpr_list), axis=0)\n",
    "tpr_std = tpr_list.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tpr + 2 * tpr_std, 1)\n",
    "tprs_lower = mean_tpr - 2 * tpr_std\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(base_fpr, mean_tpr, 'b', label='Keras (area = {:.3f})'.format(np.mean(np.array(auroc_list))))\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "with open('./output/03_mm10_evaluation_DNase.2overlap.ROC.pickle','wb') as fid:\n",
    "    pickle.dump(ax, fid)\n",
    "#plt.savefig(figure_output_name+'.ROC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRC in test set\n",
    "ax = plt.figure(figsize=(5, 5))\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "base_recall = np.linspace(0, 1, 101)\n",
    "precision_list = []\n",
    "auprc_list = []\n",
    "for i in range(len(Y)):\n",
    "    recall, precision, thresholds = sklearn.metrics.precision_recall_curve(Y[i], y_pred_list[i])\n",
    "    auprc_list.append(sklearn.metrics.average_precision_score(Y[i], y_pred_list[i]))\n",
    "    plt.plot(recall, precision, 'b', alpha=0.15)\n",
    "    precision = np.interp(base_recall, recall, precision)\n",
    "    precision[0] = 1.0\n",
    "    precision_list.append(precision)\n",
    "\n",
    "print(len(precision_list), len(precision_list[0]), len(precision_list[1]))\n",
    "precision_list = np.array(precision_list)\n",
    "mean_precision = np.mean(np.array(precision_list), axis=0)\n",
    "precision_std = precision_list.std(axis=0)\n",
    "\n",
    "precisions_upper = np.minimum(mean_precision + 2 * precision_std, 1)\n",
    "precisions_lower = mean_precision - 2 * precision_std\n",
    "\n",
    "plt.plot([0, 1], [1, 0], 'k--')\n",
    "plt.plot(base_recall, mean_precision, 'b', label='Keras (area = {:.3f})'.format(np.mean(np.array(auprc_list))))\n",
    "plt.fill_between(base_recall, precisions_lower, precisions_upper, color='grey', alpha=0.3)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.title('PRC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "with open('./output/03_mm10_evaluation_DNase.2overlap.PRC.pickle','wb') as fid:\n",
    "    pickle.dump(ax, fid)\n",
    "#plt.savefig(figure_output_name+'.PRC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated tissue forebrain auROC: 0.7614626599685677\n",
      "validated tissue heart auROC: 0.7817132452161473\n",
      "validated tissue hindbrain auROC: 0.7270741628270528\n",
      "validated tissue limb auROC: 0.7426146646980378\n",
      "validated tissue midbrain auROC: 0.7408171885115186\n",
      "validated tissue neural tube auROC: 0.7185668062428625\n",
      "\n",
      "\n",
      "validated tissue forebrain auPRC: 0.3350839933172498\n",
      "validated tissue heart auPRC: 0.2370904173003834\n",
      "validated tissue hindbrain auPRC: 0.28221288555763385\n",
      "validated tissue limb auPRC: 0.24841987408973665\n",
      "validated tissue midbrain auPRC: 0.29794634024562505\n",
      "validated tissue neural tube auPRC: 0.1892251706151935\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(samples)):\n",
    "    print(\"validated tissue \" + samples[i] + \" auROC: \" + str(auroc_list[i]))\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    print(\"validated tissue \" + samples[i] + \" auPRC: \" + str(auprc_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "accuracy_list = []\n",
    "for i in range(len(samples)):\n",
    "    \n",
    "    #fine-tuning\n",
    "    X_ft = X.copy()\n",
    "    X_ft.pop(i)\n",
    "    X_ft = np.array(X_ft)\n",
    "    X_ft = X_ft.reshape((-1, X_ft.shape[2], X_ft.shape[3], X_ft.shape[4]))\n",
    "    \n",
    "    Y_ft = Y.copy()\n",
    "    Y_ft.pop(i)\n",
    "    Y_ft = np.array(Y_ft)\n",
    "    Y_ft = Y_ft.reshape((-1, 1))\n",
    "    \n",
    "    X_ft, Y_ft = shuffle(X_ft, Y_ft, random_state=0)\n",
    "    \n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(Y_ft),\n",
    "                                                  Y_ft.flatten())\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "    \n",
    "    ft_model = create_model(width=int(window_size/10))\n",
    "    ft_model.load_weights('./saved_models/DNase_hg38.v8.h5')\n",
    "    ft_model.compile(loss='binary_crossentropy', \n",
    "                     optimizer=Adam(lr=1e-6, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=9e-5), \n",
    "                     metrics=['accuracy', auroc, auprc, f1_m, recall_m, precision_m])\n",
    "    \n",
    "    #train the model\n",
    "    history = ft_model.fit(X_ft, Y_ft,\n",
    "                        batch_size=4,\n",
    "                        epochs=150,\n",
    "                        validation_split=0.1,\n",
    "                        shuffle=True,\n",
    "                        class_weight=class_weights,\n",
    "                        callbacks=[es])\n",
    "    \n",
    "    y_pred = ft_model.predict(X[i]).ravel()\n",
    "    y_pred_list.append(y_pred)\n",
    "\n",
    "    accuracy_s = sklearn.metrics.accuracy_score(Y[i], np.rint(y_pred))\n",
    "    print(samples[i], \"validation accuracy is:\", accuracy_s)\n",
    "    accuracy_list.append(accuracy_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC in test set\n",
    "ax = plt.figure(figsize=(5, 5))\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "tpr_list = []\n",
    "auroc_list = []\n",
    "for i in range(len(Y)):\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(Y[i], y_pred_list[i])\n",
    "    auroc_list.append(sklearn.metrics.roc_auc_score(Y[i], y_pred_list[i]))\n",
    "    plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "    tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tpr_list.append(tpr)\n",
    "\n",
    "print(len(tpr_list), len(tpr_list[0]), len(tpr_list[1]))\n",
    "tpr_list = np.array(tpr_list)\n",
    "mean_tpr = np.mean(np.array(tpr_list), axis=0)\n",
    "tpr_std = tpr_list.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tpr + 2 * tpr_std, 1)\n",
    "tprs_lower = mean_tpr - 2 * tpr_std\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(base_fpr, mean_tpr, 'b', label='Keras (area = {:.3f})'.format(np.mean(np.array(auroc_list))))\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "with open('./output/03_mm10_evaluation_DNase.2overlap.oos-ROC.pickle','wb') as fid:\n",
    "    pickle.dump(ax, fid)\n",
    "#plt.savefig(figure_output_name+'.ROC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRC in test set\n",
    "ax = plt.figure(figsize=(5, 5))\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "base_recall = np.linspace(0, 1, 101)\n",
    "precision_list = []\n",
    "auprc_list = []\n",
    "for i in range(len(Y)):\n",
    "    recall, precision, thresholds = sklearn.metrics.precision_recall_curve(Y[i], y_pred_list[i])\n",
    "    auprc_list.append(sklearn.metrics.average_precision_score(Y[i], y_pred_list[i]))\n",
    "    plt.plot(recall, precision, 'b', alpha=0.15)\n",
    "    precision = np.interp(base_recall, recall, precision)\n",
    "    precision[0] = 1.0\n",
    "    precision_list.append(precision)\n",
    "\n",
    "print(len(precision_list), len(precision_list[0]), len(precision_list[1]))\n",
    "precision_list = np.array(precision_list)\n",
    "mean_precision = np.mean(np.array(precision_list), axis=0)\n",
    "precision_std = precision_list.std(axis=0)\n",
    "\n",
    "precisions_upper = np.minimum(mean_precision + 2 * precision_std, 1)\n",
    "precisions_lower = mean_precision - 2 * precision_std\n",
    "\n",
    "plt.plot([0, 1], [1, 0], 'k--')\n",
    "plt.plot(base_recall, mean_precision, 'b', label='Keras (area = {:.3f})'.format(np.mean(np.array(auprc_list))))\n",
    "plt.fill_between(base_recall, precisions_lower, precisions_upper, color='grey', alpha=0.3)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.title('PRC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "with open('./output/03_mm10_evaluation_DNase.2overlap.oos-PRC.pickle','wb') as fid:\n",
    "    pickle.dump(ax, fid)\n",
    "#plt.savefig(figure_output_name+'.PRC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated tissue forebrain auROC: 0.8591143494611586\n",
      "validated tissue heart auROC: 0.8590634432901418\n",
      "validated tissue hindbrain auROC: 0.8130930832099171\n",
      "validated tissue limb auROC: 0.8178601479646916\n",
      "validated tissue midbrain auROC: 0.8300798951573429\n",
      "validated tissue neural tube auROC: 0.8274314807765513\n",
      "overall auROC average 0.8344403999766339\n",
      "\n",
      "\n",
      "validated tissue forebrain auPRC: 0.5874635638862283\n",
      "validated tissue heart auPRC: 0.43392633225282645\n",
      "validated tissue hindbrain auPRC: 0.44039621629271347\n",
      "validated tissue limb auPRC: 0.4037318587198425\n",
      "validated tissue midbrain auPRC: 0.5056327524104473\n",
      "validated tissue neural tube auPRC: 0.37462485907971105\n",
      "overall auPRC average 0.45762926377362817\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(samples)):\n",
    "    print(\"validated tissue \" + samples[i] + \" auROC: \" + str(auroc_list[i]))\n",
    "print(\"overall auROC average \" + str(np.mean(auroc_list)))\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    print(\"validated tissue \" + samples[i] + \" auPRC: \" + str(auprc_list[i]))\n",
    "print(\"overall auPRC average \" + str(np.mean(auprc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

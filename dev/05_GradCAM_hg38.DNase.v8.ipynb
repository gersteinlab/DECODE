{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-----import packages-----#\n",
    "\n",
    "#common python packages\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import wget\n",
    "import math\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "#biological packages\n",
    "import pybedtools\n",
    "from pybedtools import featurefuncs\n",
    "import pyBigWig\n",
    "\n",
    "#machine learning packages\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten, GlobalAveragePooling2D, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.utils import Sequence, plot_model\n",
    "from keras.constraints import unit_norm\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, Callback, TensorBoard, ReduceLROnPlateau\n",
    "import keras_metrics as km\n",
    "from keras.models import load_model\n",
    "\n",
    "from models.v3 import create_model\n",
    "from models.custom_metrics import auroc, auprc, recall_m, precision_m, f1_m\n",
    "\n",
    "import cv2\n",
    "\n",
    "#notify the OS about GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files found!\n",
      "['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX']\n",
      "all files found!\n"
     ]
    }
   ],
   "source": [
    "#parsing command line arguments\n",
    "# -----parsing command line arguments-----#\n",
    "parser = argparse.ArgumentParser(description='Training CNN model to predict STARR-seq enhancers based on chromatin accessbility and histone marks')\n",
    "parser.add_argument('-w', '--cell_types', type=str, help='comma separated string of cell_types')\n",
    "parser.add_argument('-x', '--in_dir', type=str, help='input_directory')\n",
    "parser.add_argument('-y', '--cell_name', type=str, help='name of the cell')\n",
    "parser.add_argument('-z', '--out_dir', type=str, help='output_directory')\n",
    "parser.add_argument('-a', '--track1_peaks', type=str, help='chromatin accessibility peak')\n",
    "parser.add_argument('-b', '--track2_peaks', type=str, help='ChIP-seq H3K27ac peak')\n",
    "parser.add_argument('-c', '--track3_peaks', type=str, help='ChIP-seq H3K4me3 peak')\n",
    "parser.add_argument('-d', '--track4_peaks', type=str, help='ChIP-seq H3K9ac peak')\n",
    "parser.add_argument('-e', '--track5_peaks', type=str, help='ChIP-seq H3K4me1 peak')\n",
    "parser.add_argument('-f', '--track1_bw', type=str, help='chromatin accessibility bigWig')\n",
    "parser.add_argument('-g', '--track2_bw', type=str, help='ChIP-seq H3K27ac bigWig')\n",
    "parser.add_argument('-i', '--track3_bw', type=str, help='ChIP-seq H3K4me3 bigWig')\n",
    "parser.add_argument('-j', '--track4_bw', type=str, help='ChIP-seq H3K9ac bigWig')\n",
    "parser.add_argument('-k', '--track5_bw', type=str, help='ChIP-seq H3K4me1 bigWig')\n",
    "\n",
    "cell_type = \"HepG2\"\n",
    "\n",
    "#simulate command line input\n",
    "seqdir = \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/datasets/\" + cell_type + \"/\"\n",
    "cmdline_str='-w ' + \" HepG2,K562,A549,HCT116,MCF-7 \" + \\\n",
    "    ' -x ' + \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/dev/encoded_2overlap/DNase/\" + \\\n",
    "    ' -y ' + \"HepG2\" + \\\n",
    "    ' -z ' + \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/dev/output/\" + \\\n",
    "    ' -a ' + seqdir+cell_type+\".DNase-seq.narrowPeak\" + \\\n",
    "    ' -b ' + seqdir+cell_type+\".ChIP-seq.H3K27ac.narrowPeak\" + \\\n",
    "    ' -c ' + seqdir+cell_type+\".ChIP-seq.H3K4me3.narrowPeak\" + \\\n",
    "    ' -d ' + seqdir+cell_type+\".ChIP-seq.H3K9ac.narrowPeak\" + \\\n",
    "    ' -e ' + seqdir+cell_type+\".ChIP-seq.H3K4me1.narrowPeak\" + \\\n",
    "    ' -f ' + seqdir+cell_type+\".DNase-seq.bigWig\" + \\\n",
    "    ' -g ' + seqdir+cell_type+\".ChIP-seq.H3K27ac.bigWig\" + \\\n",
    "    ' -i ' + seqdir+cell_type+\".ChIP-seq.H3K4me3.bigWig\" + \\\n",
    "    ' -j ' + seqdir+cell_type+\".ChIP-seq.H3K9ac.bigWig\" + \\\n",
    "    ' -k ' + seqdir+cell_type+\".ChIP-seq.H3K4me1.bigWig\"\n",
    "\n",
    "seq_names = [\"DNase\", \"H3K27ac\", \"H3K4me3\", \"H3K9ac\", \"H3K4me1\"]\n",
    "#new_seq_names = [\"H3K4me3\", \"H3K27ac\", \"DNase\", \"H3K9ac\", \"H3K4me1\"]\n",
    "\n",
    "#check if the files are there\n",
    "args = parser.parse_args(cmdline_str.split())\n",
    "args.cell_types = args.cell_types.split(\",\")\n",
    "for cell in args.cell_types:\n",
    "    for seq in seq_names:\n",
    "        pos_file = args.in_dir + cell + \".\" + seq + \".pos.tsv\"\n",
    "        if not os.path.exists(pos_file):\n",
    "            print(pos_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "        neg_file = args.in_dir + cell + \".\" + seq + \".neg.tsv\"\n",
    "        if not os.path.exists(neg_file):\n",
    "            print(neg_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "            \n",
    "for key, value in vars(args).items():\n",
    "    if key == \"cell_types\" or key == \"in_dir\" or key == \"out_dir\" or key == \"cell_name\":\n",
    "        continue\n",
    "    else:\n",
    "        if not os.path.exists(value):\n",
    "            print(key + \" argument file does not exist\")\n",
    "            exit(1)\n",
    "print(\"all files found!\")\n",
    "\n",
    "#construct a set of autosome + X chromosome names\n",
    "chromosomes = []\n",
    "for i in range(1,23):\n",
    "    chromosomes.append(\"chr\"+str(i))\n",
    "chromosomes.append(\"chrX\")\n",
    "print(chromosomes)\n",
    "print(\"all files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(cell_types, in_dir, seq_names):\n",
    "\n",
    "    first_cell = True\n",
    "    for cell in cell_types:\n",
    "        print(cell)\n",
    "\n",
    "        pos = []\n",
    "        neg = []\n",
    "        first_seq = True\n",
    "        for seq in seq_names:\n",
    "            print(\"-\"+seq)\n",
    "\n",
    "            pos_name = in_dir+cell+\".\"+seq+\".pos.tsv\"\n",
    "            pos_mat = np.loadtxt(pos_name, delimiter='\\t')\n",
    "\n",
    "            neg_name = in_dir+cell+\".\"+seq+\".neg.tsv\"\n",
    "            neg_mat = np.loadtxt(neg_name, delimiter='\\t')\n",
    "\n",
    "            if first_seq:\n",
    "                for i in pos_mat:\n",
    "                    pos.append(np.array([i]))\n",
    "                for i in neg_mat:\n",
    "                    neg.append(np.array([i]))\n",
    "                first_seq = False\n",
    "            else:\n",
    "                for i in range(len(pos)):\n",
    "                    pos[i] = np.vstack((pos[i], pos_mat[i,]))\n",
    "                for i in range(len(neg)):\n",
    "                    neg[i] = np.vstack((neg[i], neg_mat[i,]))\n",
    "\n",
    "        if first_cell == True:\n",
    "            X_pos = np.array(pos)\n",
    "            X_neg = np.array(neg)\n",
    "            first_cell = False\n",
    "        else:\n",
    "            X_pos = np.vstack((X_pos, pos))\n",
    "            X_neg = np.vstack((X_neg, neg))\n",
    "\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    y = np.array([1 for i in range(X_pos.shape[0])] + [0 for i in range(X_pos.shape[0])]).reshape(-1,1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HepG2\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n"
     ]
    }
   ],
   "source": [
    "#render enhancers as pixels\n",
    "    #extract signals\n",
    "    #matplotlib\n",
    "X, y = get_data([cell_type], \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/dev/encoded_2overlap/DNase/\", seq_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144221, 5, 400)\n",
      "(26222, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "#X[:, [0, 2], :] = X[:, [2, 0], :]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    \"\"\"Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    \"\"\"\n",
    "    x = x.copy()\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "    return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/dev/models/v3.py:54: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  model = Model(input=[input_size], output=[pred_output])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5, 400, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 5, 400, 128)  3968        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            1032        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          1152        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 5, 400, 128)  0           conv2d_1[0][0]                   \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 400, 64)   24640       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            260         global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           320         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 5, 400, 64)   0           conv2d_2[0][0]                   \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 400, 64)   36928       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 64)           0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            260         global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           320         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 5, 400, 64)   0           conv2d_3[0][0]                   \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 5, 400, 128)  24704       multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 128)          0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            1032        global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          1152        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 5, 400, 128)  0           conv2d_4[0][0]                   \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 2, 200, 128)  0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2, 200, 64)   73792       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 64)           0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4)            260         global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           320         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 2, 200, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 200, 64)   36928       multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 64)           0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            260         global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           320         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 2, 200, 64)   0           conv2d_6[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 200, 128)  24704       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 128)          0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 8)            1032        global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          1152        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 2, 200, 128)  0           conv2d_7[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 100, 128)  0           multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12800)        0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          3277056     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            257         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,511,849\n",
      "Trainable params: 3,511,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def build_guided_model():\n",
    "#     \"\"\"Function returning modified model.\n",
    "    \n",
    "#     Changes gradient function for all ReLu activations\n",
    "#     according to Guided Backpropagation.\n",
    "#     \"\"\"\n",
    "#     if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "#         @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "#         def _GuidedBackProp(op, grad):\n",
    "#             dtype = op.inputs[0].dtype\n",
    "#             return grad * tf.cast(grad > 0., dtype) * \\\n",
    "#                    tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "#     g = tf.get_default_graph()\n",
    "#     with g.gradient_override_map({'Relu': 'GuidedBackProp'}):\n",
    "#         new_model = build_model()\n",
    "#     return new_model\n",
    "window_size = 4000\n",
    "model = create_model(width=int(window_size/10))\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "adam = Adam(lr=5e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=9e-5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, \n",
    "    metrics=['accuracy', auroc, auprc, f1_m, recall_m, precision_m])\n",
    "model.load_weights('./saved_models/DNase_hg38.v3.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_pred_1d(model, x_validation):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    layer_name = \"conv2d_5\"\n",
    "\n",
    "    y_c = model.output\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "\n",
    "    # Normalize if necessary\n",
    "    grads = normalize(grads)\n",
    "    gradient_function = K.function([model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([x_validation])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "    cam = cv2.resize(cam, (200, 1), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "#     cam = cam / cam.max()\n",
    "    return cam\n",
    "\n",
    "def cam_pred_5d(model, x_validation):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    layer_name = \"conv2d_3\"\n",
    "\n",
    "    y_c = model.output\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "\n",
    "    # Normalize if necessary\n",
    "    grads = normalize(grads)\n",
    "    gradient_function = K.function([model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([x_validation])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "    cam = cv2.resize(cam, (200, 5), cv2.INTER_LINEAR)\n",
    "#     print(cam.shape)\n",
    "    cam = np.maximum(cam, 0)\n",
    "#     cam = cam / cam.max()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 4 is out of bounds for array of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2e6b9c05203c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0mout_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0mshape_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 4 is out of bounds for array of dimension 4"
     ]
    }
   ],
   "source": [
    "x_validation = np.expand_dims(np.array(X), axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_idx in range(0, 100):\n",
    "    print(y[window_idx]) #98\n",
    "    plt.plot(cam_pred_1d(model, np.expand_dims(x_validation[window_idx], axis=0))[0])\n",
    "    plt.hlines(0.04443, 0, 200, color=\"red\", alpha=0.8)\n",
    "    plt.text(x=10, y=0.07, s='refine cutoff', fontsize=12)\n",
    "    plt.xticks([])\n",
    "    plt.show();\n",
    "\n",
    "    cam_5d = cam_pred_5d(model, np.expand_dims(x_validation[window_idx], axis=0))\n",
    "    for i in [2,1,0,3,4]:\n",
    "        plt.plot(cam_5d[i,], label=seq_names[i])\n",
    "    plt.legend()\n",
    "    plt.xticks([])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_pred_multi_1d(model, X):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    layer_name = \"conv2d_5\"\n",
    "\n",
    "    y_c = model.output\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "\n",
    "    # Normalize if necessary\n",
    "    grads = normalize(grads)\n",
    "    gradient_function = K.function([model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([X])\n",
    "    weights = np.mean(grads_val, axis=(1, 2))\n",
    "\n",
    "    all_cam = []\n",
    "    for i in range(len(weights)):\n",
    "        cam = np.dot(output[i], weights[i])\n",
    "        cam = cv2.resize(cam, (200, 1), cv2.INTER_LINEAR)\n",
    "        cam = np.maximum(cam, 0)\n",
    "        all_cam.append(cam[0])\n",
    "\n",
    "    all_cam = np.array(all_cam)\n",
    "    return all_cam\n",
    "\n",
    "def cam_pred_multi_5d(model, X):\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    layer_name = \"conv2d_3\"\n",
    "\n",
    "    y_c = model.output\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "\n",
    "    # Normalize if necessary\n",
    "    grads = normalize(grads)\n",
    "    gradient_function = K.function([model.input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([X])\n",
    "    weights = np.mean(grads_val, axis=(1, 2))\n",
    "\n",
    "    all_cam = []\n",
    "    for i in range(len(weights)):\n",
    "        cam = np.dot(output[i], weights[i])\n",
    "        cam = cv2.resize(cam, (200, 5), cv2.INTER_LINEAR)\n",
    "        cam = np.maximum(cam, 0)\n",
    "        all_cam.append(cam[0])\n",
    "\n",
    "    all_cam = np.array(all_cam)\n",
    "    return all_cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144221, 5, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "pos_len = len(y[y==1])\n",
    "print(x_validation.shape)\n",
    "# pos_cam = cam_pred_multi_1d(model, x_validation[0:1000])\n",
    "# neg_cam = cam_pred_multi_1d(model, x_validation[pos_len:pos_len+1000])\n",
    "# print(pos_cam.shape)\n",
    "# print(neg_cam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1000,128,5,400] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e94ab6a43d35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpos_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mneg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mend_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpos_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_pred_multi_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mneg_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_pred_multi_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpos_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_cam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-79fe6633f02a>\u001b[0m in \u001b[0;36mcam_pred_multi_1d\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgradient_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1000,128,5,400] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "pos_cam = []\n",
    "neg_cam = []\n",
    "for i in range(int(pos_len/1000) + 1):\n",
    "    if (i % 10 == 0):\n",
    "        print(str(i) + \",000\")\n",
    "    if ((i+1)*1000 > pos_len):\n",
    "        end_idx = pos_len\n",
    "    else:\n",
    "        end_idx = (i+1)*1000\n",
    "    pos_idx = slice(i*1000, end_idx)\n",
    "    neg_idx = slice(pos_len + i*1000, pos_len + end_idx)\n",
    "    pos_cam.extend(cam_pred_multi_1d(model, x_validation[pos_idx]))\n",
    "    neg_cam.extend(cam_pred_multi_1d(model, x_validation[neg_idx]))\n",
    "pos_cam = np.array(pos_cam)\n",
    "neg_cam = np.array(neg_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(pos_cam, showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(neg_cam, showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

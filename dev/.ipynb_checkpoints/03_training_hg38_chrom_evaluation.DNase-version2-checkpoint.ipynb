{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-----import packages-----#\n",
    "\n",
    "#common python packages\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import wget\n",
    "import math\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "#biological packages\n",
    "import pybedtools\n",
    "from pybedtools import featurefuncs\n",
    "import pyBigWig\n",
    "\n",
    "#machine learning packages\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.utils import Sequence, plot_model\n",
    "from keras.constraints import unit_norm\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, Callback, TensorBoard, ReduceLROnPlateau\n",
    "import keras_metrics as km\n",
    "from keras.models import load_model\n",
    "\n",
    "#notify the OS about GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    K.clear_session()\n",
    "    pool2_list = []\n",
    "    merge_list = []\n",
    "\n",
    "    input_size = Input(shape=(5, 200, 1))\n",
    "    conv1_ = Conv2D(128, (3, 10), padding='same',activation='relu')(input_size)\n",
    "    conv2_ = Conv2D(64, (3, 1), padding='same',activation='relu')(conv1_)\n",
    "    conv3_ = Conv2D(64, (3, 3), padding='same',activation='relu')(conv2_)\n",
    "    conv4_ = Conv2D(128, (3, 1), padding='same',activation='relu')(conv3_)\n",
    "    pool1  = MaxPooling2D(pool_size=(1, 2))(conv4_)\n",
    "    conv5_ = Conv2D(64, (3, 3), padding='same',activation='relu')(pool1)\n",
    "    conv6_ = Conv2D(64, (3, 3), padding='same',activation='relu')(conv5_)\n",
    "    conv7_ = Conv2D(128, (3, 1), padding='same',activation='relu')(conv6_)\n",
    "    pool2  = MaxPooling2D(pool_size=(1, 2))(conv7_)\n",
    "\n",
    "    x = Flatten()(pool2)\n",
    "    dense1_ = Dense(256, activation='relu')\n",
    "    dense1  = dense1_(x)\n",
    "    x = Dropout(0.4)(dense1)\n",
    "    dense2  = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.4)(dense2)\n",
    "    dense3 = Dense(32, activation='relu')(x)\n",
    "    pred_output = Dense(1, activation='sigmoid')(dense3)\n",
    "    model = Model(input=[input_size], output=[pred_output])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files found!\n",
      "['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX']\n",
      "all files found!\n"
     ]
    }
   ],
   "source": [
    "#parsing command line arguments\n",
    "# -----parsing command line arguments-----#\n",
    "parser = argparse.ArgumentParser(description='Training CNN model to predict STARR-seq enhancers based on chromatin accessbility and histone marks')\n",
    "parser.add_argument('-w', '--cell_types', type=str, help='comma separated string of cell_types')\n",
    "parser.add_argument('-x', '--in_dir', type=str, help='input_directory')\n",
    "parser.add_argument('-y', '--cell_name', type=str, help='name of the cell')\n",
    "parser.add_argument('-z', '--out_dir', type=str, help='output_directory')\n",
    "parser.add_argument('-a', '--track1_peaks', type=str, help='chromatin accessibility peak')\n",
    "parser.add_argument('-b', '--track2_peaks', type=str, help='ChIP-seq H3K27ac peak')\n",
    "parser.add_argument('-c', '--track3_peaks', type=str, help='ChIP-seq H3K4me3 peak')\n",
    "parser.add_argument('-d', '--track4_peaks', type=str, help='ChIP-seq H3K9ac peak')\n",
    "parser.add_argument('-e', '--track5_peaks', type=str, help='ChIP-seq H3K4me1 peak')\n",
    "parser.add_argument('-f', '--track1_bw', type=str, help='chromatin accessibility bigWig')\n",
    "parser.add_argument('-g', '--track2_bw', type=str, help='ChIP-seq H3K27ac bigWig')\n",
    "parser.add_argument('-i', '--track3_bw', type=str, help='ChIP-seq H3K4me3 bigWig')\n",
    "parser.add_argument('-j', '--track4_bw', type=str, help='ChIP-seq H3K9ac bigWig')\n",
    "parser.add_argument('-k', '--track5_bw', type=str, help='ChIP-seq H3K4me1 bigWig')\n",
    "\n",
    "cell_type = \"NPC\"\n",
    "\n",
    "#simulate command line input\n",
    "seqdir = \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/datasets/\" + cell_type + \"/\"\n",
    "cmdline_str='-w ' + \" HepG2,K562,A549,HCT116,MCF-7 \" + \\\n",
    "    ' -x ' + \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/pipeline/encoded/DNase/\" + \\\n",
    "    ' -y ' + \"NPC\" + \\\n",
    "    ' -z ' + \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/pipeline/encoded/DNase/\" + \\\n",
    "    ' -a ' + seqdir+cell_type+\".DNase-seq.narrowPeak\" + \\\n",
    "    ' -b ' + seqdir+cell_type+\".ChIP-seq.H3K27ac.narrowPeak\" + \\\n",
    "    ' -c ' + seqdir+cell_type+\".ChIP-seq.H3K4me3.narrowPeak\" + \\\n",
    "    ' -d ' + seqdir+cell_type+\".ChIP-seq.H3K9ac.narrowPeak\" + \\\n",
    "    ' -e ' + seqdir+cell_type+\".ChIP-seq.H3K4me1.narrowPeak\" + \\\n",
    "    ' -f ' + seqdir+cell_type+\".DNase-seq.bigWig\" + \\\n",
    "    ' -g ' + seqdir+cell_type+\".ChIP-seq.H3K27ac.bigWig\" + \\\n",
    "    ' -i ' + seqdir+cell_type+\".ChIP-seq.H3K4me3.bigWig\" + \\\n",
    "    ' -j ' + seqdir+cell_type+\".ChIP-seq.H3K9ac.bigWig\" + \\\n",
    "    ' -k ' + seqdir+cell_type+\".ChIP-seq.H3K4me1.bigWig\"\n",
    "\n",
    "seq_names = [\"DNase\", \"H3K27ac\", \"H3K4me3\", \"H3K9ac\", \"H3K4me1\"]\n",
    "\n",
    "#check if the files are there\n",
    "args = parser.parse_args(cmdline_str.split())\n",
    "args.cell_types = args.cell_types.split(\",\")\n",
    "for cell in args.cell_types:\n",
    "    for seq in seq_names:\n",
    "        pos_file = args.in_dir + cell + \".\" + seq + \".pos.tsv\"\n",
    "        if not os.path.exists(pos_file):\n",
    "            print(pos_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "        neg_file = args.in_dir + cell + \".\" + seq + \".neg.tsv\"\n",
    "        if not os.path.exists(neg_file):\n",
    "            print(neg_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "            \n",
    "for key, value in vars(args).items():\n",
    "    if key == \"cell_types\" or key == \"in_dir\" or key == \"out_dir\" or key == \"cell_name\":\n",
    "        continue\n",
    "    else:\n",
    "        if not os.path.exists(value):\n",
    "            print(key + \" argument file does not exist\")\n",
    "            exit(1)\n",
    "print(\"all files found!\")\n",
    "\n",
    "#construct a set of autosome + X chromosome names\n",
    "chromosomes = []\n",
    "for i in range(1,23):\n",
    "    chromosomes.append(\"chr\"+str(i))\n",
    "chromosomes.append(\"chrX\")\n",
    "print(chromosomes)\n",
    "print(\"all files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HepG2\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n",
      "K562\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n",
      "A549\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n",
      "HCT116\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n",
      "MCF-7\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n",
      "(198250, 5, 200)\n",
      "(198250, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_data(cell_types, in_dir, seq_names):\n",
    "\n",
    "    first_cell = True\n",
    "    for cell in cell_types:\n",
    "        print(cell)\n",
    "\n",
    "        pos = []\n",
    "        neg = []\n",
    "        first_seq = True\n",
    "        for seq in seq_names:\n",
    "            print(\"-\"+seq)\n",
    "\n",
    "            pos_name = in_dir+cell+\".\"+seq+\".pos.tsv\"\n",
    "            pos_mat = np.loadtxt(pos_name, delimiter='\\t')\n",
    "\n",
    "            neg_name = in_dir+cell+\".\"+seq+\".neg.tsv\"\n",
    "            neg_mat = np.loadtxt(neg_name, delimiter='\\t')\n",
    "\n",
    "            if first_seq:\n",
    "                for i in pos_mat:\n",
    "                    pos.append(np.array([i]))\n",
    "                for i in neg_mat:\n",
    "                    neg.append(np.array([i]))\n",
    "                first_seq = False\n",
    "            else:\n",
    "                for i in range(len(pos)):\n",
    "                    pos[i] = np.vstack((pos[i], pos_mat[i,]))\n",
    "                for i in range(len(neg)):\n",
    "                    neg[i] = np.vstack((neg[i], neg_mat[i,]))\n",
    "\n",
    "        if first_cell == True:\n",
    "            X_pos = np.array(pos)\n",
    "            X_neg = np.array(neg)\n",
    "            first_cell = False\n",
    "        else:\n",
    "            X_pos = np.vstack((X_pos, pos))\n",
    "            X_neg = np.vstack((X_neg, neg))\n",
    "\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    y = np.array([1 for i in range(X_pos.shape[0])] + [0 for i in range(X_pos.shape[0])]).reshape(-1,1)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = get_data(args.cell_types, args.in_dir, seq_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred, curve=\"ROC\", summation_method='careful_interpolation')[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "def auprc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred, curve='PR', summation_method='careful_interpolation')[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n",
      "/gpfs/ysm/project/zc264/conda_envs/old_keras_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5, 200, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 200, 128)       3968      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 200, 64)        24640     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 200, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 200, 128)       24704     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 100, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 100, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 100, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 100, 128)       24704     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 50, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8192256   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,454,977\n",
      "Trainable params: 8,454,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "198250/198250 [==============================] - 117s 590us/step - loss: 0.0907 - acc: 0.9721 - auroc: 0.9824 - auprc: 0.9734 - f1_m: 0.9724 - recall_m: 0.9903 - precision_m: 0.9575\n",
      "Epoch 2/30\n",
      "198250/198250 [==============================] - 105s 531us/step - loss: 0.0554 - acc: 0.9839 - auroc: 0.9923 - auprc: 0.9878 - f1_m: 0.9834 - recall_m: 0.9942 - precision_m: 0.9740\n",
      "Epoch 3/30\n",
      "198250/198250 [==============================] - 105s 530us/step - loss: 0.0470 - acc: 0.9862 - auroc: 0.9940 - auprc: 0.9905 - f1_m: 0.9858 - recall_m: 0.9946 - precision_m: 0.9780\n",
      "Epoch 4/30\n",
      "198250/198250 [==============================] - 105s 530us/step - loss: 0.0428 - acc: 0.9873 - auroc: 0.9950 - auprc: 0.9920 - f1_m: 0.9870 - recall_m: 0.9948 - precision_m: 0.9802\n",
      "Epoch 5/30\n",
      "198250/198250 [==============================] - 105s 530us/step - loss: 0.0390 - acc: 0.9886 - auroc: 0.9956 - auprc: 0.9930 - f1_m: 0.9883 - recall_m: 0.9952 - precision_m: 0.9822\n",
      "Epoch 6/30\n",
      "198250/198250 [==============================] - 105s 530us/step - loss: 0.0366 - acc: 0.9893 - auroc: 0.9960 - auprc: 0.9936 - f1_m: 0.9890 - recall_m: 0.9952 - precision_m: 0.9835\n",
      "Epoch 7/30\n",
      "198250/198250 [==============================] - 105s 531us/step - loss: 0.0347 - acc: 0.9898 - auroc: 0.9963 - auprc: 0.9942 - f1_m: 0.9895 - recall_m: 0.9952 - precision_m: 0.9846\n",
      "Epoch 8/30\n",
      "198250/198250 [==============================] - 106s 533us/step - loss: 0.0331 - acc: 0.9903 - auroc: 0.9966 - auprc: 0.9946 - f1_m: 0.9900 - recall_m: 0.9956 - precision_m: 0.9851\n",
      "Epoch 9/30\n",
      "198250/198250 [==============================] - 106s 534us/step - loss: 0.0315 - acc: 0.9908 - auroc: 0.9968 - auprc: 0.9949 - f1_m: 0.9905 - recall_m: 0.9959 - precision_m: 0.9858\n",
      "Epoch 10/30\n",
      "198250/198250 [==============================] - 106s 536us/step - loss: 0.0303 - acc: 0.9911 - auroc: 0.9970 - auprc: 0.9951 - f1_m: 0.9908 - recall_m: 0.9957 - precision_m: 0.9866\n",
      "Epoch 11/30\n",
      "198250/198250 [==============================] - 106s 536us/step - loss: 0.0289 - acc: 0.9917 - auroc: 0.9971 - auprc: 0.9954 - f1_m: 0.9915 - recall_m: 0.9961 - precision_m: 0.9875\n",
      "Epoch 12/30\n",
      "198250/198250 [==============================] - 107s 538us/step - loss: 0.0278 - acc: 0.9919 - auroc: 0.9973 - auprc: 0.9956 - f1_m: 0.9917 - recall_m: 0.9963 - precision_m: 0.9877\n",
      "Epoch 13/30\n",
      "198250/198250 [==============================] - 106s 536us/step - loss: 0.0266 - acc: 0.9923 - auroc: 0.9974 - auprc: 0.9958 - f1_m: 0.9921 - recall_m: 0.9964 - precision_m: 0.9883\n",
      "Epoch 14/30\n",
      "198250/198250 [==============================] - 106s 535us/step - loss: 0.0255 - acc: 0.9927 - auroc: 0.9975 - auprc: 0.9960 - f1_m: 0.9925 - recall_m: 0.9966 - precision_m: 0.9890\n",
      "Epoch 15/30\n",
      "198250/198250 [==============================] - 106s 535us/step - loss: 0.0246 - acc: 0.9931 - auroc: 0.9976 - auprc: 0.9961 - f1_m: 0.9929 - recall_m: 0.9970 - precision_m: 0.9893\n",
      "Epoch 16/30\n",
      "198250/198250 [==============================] - 106s 535us/step - loss: 0.0237 - acc: 0.9933 - auroc: 0.9977 - auprc: 0.9963 - f1_m: 0.9931 - recall_m: 0.9968 - precision_m: 0.9898\n",
      "Epoch 17/30\n",
      "198250/198250 [==============================] - 106s 535us/step - loss: 0.0230 - acc: 0.9935 - auroc: 0.9978 - auprc: 0.9964 - f1_m: 0.9934 - recall_m: 0.9970 - precision_m: 0.9902\n",
      "Epoch 18/30\n",
      "198250/198250 [==============================] - 106s 533us/step - loss: 0.0217 - acc: 0.9939 - auroc: 0.9978 - auprc: 0.9965 - f1_m: 0.9937 - recall_m: 0.9972 - precision_m: 0.9907\n",
      "Epoch 19/30\n",
      "198250/198250 [==============================] - 105s 532us/step - loss: 0.0211 - acc: 0.9941 - auroc: 0.9979 - auprc: 0.9966 - f1_m: 0.9940 - recall_m: 0.9973 - precision_m: 0.9912\n",
      "Epoch 20/30\n",
      "198250/198250 [==============================] - 106s 533us/step - loss: 0.0198 - acc: 0.9944 - auroc: 0.9980 - auprc: 0.9967 - f1_m: 0.9942 - recall_m: 0.9974 - precision_m: 0.9914\n",
      "Epoch 21/30\n",
      "198250/198250 [==============================] - 106s 532us/step - loss: 0.0191 - acc: 0.9947 - auroc: 0.9980 - auprc: 0.9968 - f1_m: 0.9946 - recall_m: 0.9976 - precision_m: 0.9919\n",
      "Epoch 22/30\n",
      "198250/198250 [==============================] - 106s 533us/step - loss: 0.0183 - acc: 0.9949 - auroc: 0.9981 - auprc: 0.9969 - f1_m: 0.9947 - recall_m: 0.9976 - precision_m: 0.9922\n",
      "Epoch 23/30\n",
      "198250/198250 [==============================] - 106s 534us/step - loss: 0.0177 - acc: 0.9951 - auroc: 0.9982 - auprc: 0.9970 - f1_m: 0.9950 - recall_m: 0.9978 - precision_m: 0.9924\n",
      "Epoch 24/30\n",
      "198250/198250 [==============================] - 105s 532us/step - loss: 0.0169 - acc: 0.9954 - auroc: 0.9982 - auprc: 0.9971 - f1_m: 0.9952 - recall_m: 0.9981 - precision_m: 0.9927\n",
      "Epoch 25/30\n",
      "198250/198250 [==============================] - 106s 534us/step - loss: 0.0162 - acc: 0.9957 - auroc: 0.9983 - auprc: 0.9972 - f1_m: 0.9955 - recall_m: 0.9980 - precision_m: 0.9934\n",
      "Epoch 26/30\n",
      "198250/198250 [==============================] - 105s 529us/step - loss: 0.0158 - acc: 0.9957 - auroc: 0.9983 - auprc: 0.9972 - f1_m: 0.9956 - recall_m: 0.9980 - precision_m: 0.9935\n",
      "Epoch 27/30\n",
      "198250/198250 [==============================] - 105s 529us/step - loss: 0.0151 - acc: 0.9959 - auroc: 0.9984 - auprc: 0.9973 - f1_m: 0.9957 - recall_m: 0.9982 - precision_m: 0.9936\n",
      "Epoch 28/30\n",
      "198250/198250 [==============================] - 105s 531us/step - loss: 0.0144 - acc: 0.9960 - auroc: 0.9984 - auprc: 0.9974 - f1_m: 0.9959 - recall_m: 0.9982 - precision_m: 0.9939\n",
      "Epoch 29/30\n",
      "198250/198250 [==============================] - 105s 530us/step - loss: 0.0138 - acc: 0.9963 - auroc: 0.9985 - auprc: 0.9975 - f1_m: 0.9962 - recall_m: 0.9984 - precision_m: 0.9942\n",
      "Epoch 30/30\n",
      "198250/198250 [==============================] - 105s 529us/step - loss: 0.0134 - acc: 0.9963 - auroc: 0.9985 - auprc: 0.9975 - f1_m: 0.9962 - recall_m: 0.9984 - precision_m: 0.9943\n"
     ]
    }
   ],
   "source": [
    "X, y = shuffle(X, y, random_state=0)\n",
    "x_train = np.expand_dims(X, axis=4)\n",
    "y_train = y\n",
    "\n",
    "# construct the model\n",
    "model = create_model()\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=9e-5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, \n",
    "    metrics=['accuracy', auroc, auprc, f1_m, recall_m, precision_m])\n",
    "\n",
    "#train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_split=0.0,\n",
    "    shuffle=True)\n",
    "\n",
    "model.save('hg38_evaluation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/pipeline/encoded/DNase/NPC.validation_regions.bed)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----IO and preprocess the signal files-----#\n",
    "chromAcc = pybedtools.BedTool(args.track1_peaks).sort().merge()\n",
    "# chip1 = pybedtools.BedTool(args.track2_peaks).sort().merge()\n",
    "# chip2 = pybedtools.BedTool(args.track3_peaks).sort().merge()\n",
    "# chip3 = pybedtools.BedTool(args.track4_peaks).sort().merge()\n",
    "# chip4 = pybedtools.BedTool(args.track5_peaks).sort().merge()\n",
    "validation_regions = chromAcc.filter(lambda x: x.chrom in chromosomes)\n",
    "validation_regions = validation_regions.each(pybedtools.featurefuncs.midpoint)\n",
    "validation_regions = validation_regions.slop(b=3000/2, genome=\"hg38\")\n",
    "validation_regions = validation_regions.filter(pybedtools.featurefuncs.greater_than, 3000-1)\n",
    "validation_regions = validation_regions.sort()\n",
    "validation_regions.saveas(args.out_dir + args.cell_name + \".validation_regions.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished chromACC\n",
      "finished chip1\n",
      "finished chip2\n",
      "finished chip3\n",
      "finished chip4\n"
     ]
    }
   ],
   "source": [
    "chromAcc_bw = pyBigWig.open(args.track1_bw)\n",
    "chip1_bw = pyBigWig.open(args.track2_bw)\n",
    "chip2_bw = pyBigWig.open(args.track3_bw)\n",
    "chip3_bw = pyBigWig.open(args.track4_bw)\n",
    "chip4_bw = pyBigWig.open(args.track5_bw)\n",
    "\n",
    "def bigWigAverageOverBed(x, bigwig):\n",
    "    return bigwig.stats(x.chrom, x.start, x.stop, nBins=200)\n",
    "\n",
    "def get_signal(region, bigwig):\n",
    "    return [bigWigAverageOverBed(x, bigwig) for x in region]\n",
    "\n",
    "valid_chromAcc = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".\" + \"validation_regions.bed\"), chromAcc_bw)\n",
    "print(\"finished chromACC\")\n",
    "valid_chip1 = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".\" + \"validation_regions.bed\"), chip1_bw)\n",
    "print(\"finished chip1\")\n",
    "valid_chip2 = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".\" + \"validation_regions.bed\"), chip2_bw)\n",
    "print(\"finished chip2\")\n",
    "valid_chip3 = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".\" + \"validation_regions.bed\"), chip3_bw)\n",
    "print(\"finished chip3\")\n",
    "valid_chip4 = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".\" + \"validation_regions.bed\"), chip4_bw)\n",
    "print(\"finished chip4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chromAcc_bw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b838761d91b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#free some memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mchromAcc_bw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mchromAcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mchip1_bw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mchip2_bw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chromAcc_bw' is not defined"
     ]
    }
   ],
   "source": [
    "#free some memory\n",
    "del chromAcc_bw\n",
    "del chromAcc\n",
    "del chip1_bw\n",
    "del chip2_bw\n",
    "del chip3_bw\n",
    "del chip4_bw\n",
    "del x_train\n",
    "del y_train\n",
    "del X\n",
    "del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222642, 5, 200)\n"
     ]
    }
   ],
   "source": [
    "#reformat the validation values\n",
    "valid_chromAcc = [np.array(i) for i in valid_chromAcc]\n",
    "valid_chip1 = [np.array(i) for i in valid_chip1]\n",
    "valid_chip2 = [np.array(i) for i in valid_chip2]\n",
    "valid_chip3 = [np.array(i) for i in valid_chip3]\n",
    "valid_chip4 = [np.array(i) for i in valid_chip4]\n",
    "\n",
    "x_validation = []\n",
    "for i in range(validation_regions.count()):\n",
    "    x_validation.append(np.array([valid_chromAcc[i], valid_chip1[i], valid_chip2[i], valid_chip3[i], valid_chip4[i]]))\n",
    "x_validation = np.nan_to_num(np.array(x_validation, dtype=float))\n",
    "print(x_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = TemporaryFile()\n",
    "np.save(outfile, x_validation)\n",
    "np.save(\"hg38_evaluation.out\", x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#free some memory\n",
    "del valid_chromAcc\n",
    "del valid_chip1\n",
    "del valid_chip2\n",
    "del valid_chip3\n",
    "del valid_chip4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = np.expand_dims(x_validation, axis=4)\n",
    "print(x_validation.shape)\n",
    "model = load_model('hg38_evaluation.h5', custom_objects={\"auroc\": auroc, \n",
    "                                                         \"auprc\": auroc, \n",
    "                                                         \"f1_m\": f1_m, \n",
    "                                                         \"recall_m\": recall_m,\n",
    "                                                         \"precision_m\": precision_m})\n",
    "y_validation = model.predict(x_validation).ravel()\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222642,)\n"
     ]
    }
   ],
   "source": [
    "del x_validation\n",
    "gc.collect()\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.out_dir + args.cell_name + \".\" + \"validation_regions.bed\", sep=\"\\t\",header=None)\n",
    "df[4] = y_validation\n",
    "df.to_csv(args.out_dir + args.cell_name + \".\" + \"prediction_regions.bed\", sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromAcc_bw = pyBigWig.open(args.track1_bw)\n",
    "chip1_bw = pyBigWig.open(args.track2_bw)\n",
    "chip2_bw = pyBigWig.open(args.track3_bw)\n",
    "chip3_bw = pyBigWig.open(args.track4_bw)\n",
    "chip4_bw = pyBigWig.open(args.track5_bw)\n",
    "\n",
    "def pos_filter(feature):\n",
    "    return feature.score == \"1\"\n",
    "\n",
    "def neg_filter(feature):\n",
    "    return feature.score == \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(pos_filter), chromAcc_bw)\n",
    "neg_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(neg_filter), chromAcc_bw)\n",
    "plt.boxplot(pos_sig_mat, showfliers=False);\n",
    "plt.boxplot(neg_sig_mat, showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(pos_filter), chip1_bw)\n",
    "neg_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(neg_filter), chip1_bw)\n",
    "plt.boxplot(pos_sig_mat, showfliers=False);\n",
    "plt.boxplot(neg_sig_mat, showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(pos_filter), chip2_bw)\n",
    "neg_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(neg_filter), chip2_bw)\n",
    "plt.boxplot(pos_sig_mat, showfliers=False);\n",
    "plt.boxplot(neg_sig_mat, showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(pos_filter), chip3_bw)\n",
    "neg_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(neg_filter), chip3_bw)\n",
    "plt.boxplot(pos_sig_mat, showfliers=False);\n",
    "plt.boxplot(neg_sig_mat, showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(pos_filter), chip4_bw)\n",
    "neg_sig_mat = get_signal(pybedtools.BedTool(args.out_dir + args.cell_name + \".prediction_regions.bed\").filter(neg_filter), chip4_bw)\n",
    "plt.boxplot(pos_sig_mat, showfliers=False);\n",
    "plt.boxplot(neg_sig_mat, showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

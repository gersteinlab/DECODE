{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-----import packages-----#\n",
    "\n",
    "#common python packages\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import wget\n",
    "import math\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "#machine learning packages\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten, GlobalAveragePooling2D, Multiply\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.utils import Sequence, plot_model\n",
    "from keras.constraints import unit_norm\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, Callback, TensorBoard, ReduceLROnPlateau\n",
    "import keras_metrics as km\n",
    "\n",
    "from models.v8 import create_model\n",
    "from models.custom_metrics import auroc, auprc, recall_m, precision_m, f1_m\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#notify the OS about GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all files found!\n"
     ]
    }
   ],
   "source": [
    "#parsing command line arguments\n",
    "# -----parsing command line arguments-----#\n",
    "parser = argparse.ArgumentParser(description='Training CNN model to predict STARR-seq enhancers based on chromatin accessbility and histone marks')\n",
    "parser.add_argument('-c', '--cell_types', type=str, help='comma separated string of cell_types')\n",
    "parser.add_argument('-i', '--in_dir', type=str, help='directory containing 01_data_encoding intermediate tsv files')\n",
    "\n",
    "#simulate command line input\n",
    "cmdline_str='-c ' + \" HepG2,K562,A549,HCT116,MCF-7 \" + \\\n",
    "    ' -i ' + \"/gpfs/ysm/scratch60/gerstein/zc264/ChromVar/enhancer-prediction/encode/dev/encoded_2overlap/DNase/\"\n",
    "\n",
    "seq_names = [\"DNase\", \"H3K27ac\", \"H3K4me3\", \"H3K9ac\", \"H3K4me1\"]\n",
    "\n",
    "#check if the files are there\n",
    "args = parser.parse_args(cmdline_str.split())\n",
    "args.cell_types = args.cell_types.split(\",\")\n",
    "for cell in args.cell_types:\n",
    "    for seq in seq_names:\n",
    "        pos_file = args.in_dir + cell + \".\" + seq + \".pos.tsv\"\n",
    "        if not os.path.exists(pos_file):\n",
    "            print(pos_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "        neg_file = args.in_dir + cell + \".\" + seq + \".neg.tsv\"\n",
    "        if not os.path.exists(neg_file):\n",
    "            print(neg_file + \" file does not exist\")\n",
    "            exit(1)\n",
    "print(\"all files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HepG2\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n",
      "K562\n",
      "-DNase\n",
      "-H3K27ac\n",
      "-H3K4me3\n",
      "-H3K9ac\n",
      "-H3K4me1\n",
      "A549\n",
      "-DNase\n"
     ]
    }
   ],
   "source": [
    "def get_data(cell_types, in_dir, seq_names):\n",
    "\n",
    "    first_cell = True\n",
    "    for cell in cell_types:\n",
    "        print(cell)\n",
    "\n",
    "        pos = []\n",
    "        neg = []\n",
    "        first_seq = True\n",
    "        for seq in seq_names:\n",
    "            print(\"-\"+seq)\n",
    "\n",
    "            pos_name = in_dir+cell+\".\"+seq+\".pos.tsv\"\n",
    "            pos_mat = np.loadtxt(pos_name, delimiter='\\t')\n",
    "\n",
    "            neg_name = in_dir+cell+\".\"+seq+\".neg.tsv\"\n",
    "            neg_mat = np.loadtxt(neg_name, delimiter='\\t')\n",
    "\n",
    "            if first_seq:\n",
    "                for i in pos_mat:\n",
    "                    pos.append(np.array([i]))\n",
    "                for i in neg_mat:\n",
    "                    neg.append(np.array([i]))\n",
    "                first_seq = False\n",
    "            else:\n",
    "                for i in range(len(pos)):\n",
    "                    pos[i] = np.vstack((pos[i], pos_mat[i,]))\n",
    "                for i in range(len(neg)):\n",
    "                    neg[i] = np.vstack((neg[i], neg_mat[i,]))\n",
    "\n",
    "        if first_cell == True:\n",
    "            X_pos = np.array(pos)\n",
    "            X_neg = np.array(neg)\n",
    "            first_cell = False\n",
    "        else:\n",
    "            X_pos = np.vstack((X_pos, pos))\n",
    "            X_neg = np.vstack((X_neg, neg))\n",
    "\n",
    "    X = np.vstack((X_pos, X_neg))\n",
    "    y = np.array([1 for i in range(X_pos.shape[0])] + [0 for i in range(X_neg.shape[0])]).reshape(-1,1)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = get_data(args.cell_types, args.in_dir, seq_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold division of the data\n",
    "kf = sklearn.model_selection.KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "#collect the output of the kfolds\n",
    "history_list = []\n",
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "kskip = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over each fold of data\n",
    "for train_index, test_index in kf.split(y):\n",
    "    \n",
    "    x_train = np.expand_dims(X[train_index], axis=4)\n",
    "    x_test = np.expand_dims(X[test_index], axis=4)\n",
    "    print(train_index[0:100])\n",
    "    print(train_index[0:100])\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # construct the model\n",
    "    model = create_model(width=400)\n",
    "\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=9e-5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, \n",
    "        metrics=['accuracy', auroc, auprc, f1_m, recall_m, precision_m])\n",
    "\n",
    "    #train the model\n",
    "    history_list.append(model.fit(x_train, y_train,\n",
    "                batch_size=32,\n",
    "                epochs=30,\n",
    "                validation_split=0.0,\n",
    "                shuffle=True))\n",
    "\n",
    "    # predict the results\n",
    "    y_pred = model.predict(x_test).ravel()\n",
    "    y_pred_list.append(y_pred)\n",
    "    y_test_list.append(y_test.ravel())\n",
    "\n",
    "    accuracy_s = sklearn.metrics.accuracy_score(y_test, np.rint(y_pred))\n",
    "    accuracy_list.append(accuracy_s)\n",
    "\n",
    "    #iterate k fold counter\n",
    "    kskip = kskip + 1\n",
    "\n",
    "    #delete the model so the variable is cleared\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_out = []\n",
    "y_pred_out = []\n",
    "for j in range(len(y_test_list)):\n",
    "    print(len(y_test_list[j]), len(y_pred_list[j]), type(y_test_list[j]))\n",
    "    y_test_out.extend(y_test_list[j])\n",
    "    y_pred_out.extend(y_pred_list[j])\n",
    "\n",
    "# plot accuracy over time\n",
    "plt.figure()\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "history_acc = np.array([np.array(h.history['acc']) for h in history_list])\n",
    "mean_history_acc = np.mean(history_acc, axis=0)\n",
    "\n",
    "plt.plot(mean_history_acc, label='(5cv_acc = {:.3f})'.format(np.mean(np.array(accuracy_list))))\n",
    "plt.title('training accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "#plt.savefig(figure_output_name+'.accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss over time\n",
    "plt.figure()\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "history_loss = np.array([np.array(h.history['loss']) for h in history_list])\n",
    "mean_history_loss = np.mean(history_loss, axis=0)\n",
    "\n",
    "plt.plot(mean_history_loss)\n",
    "plt.title('training loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "#plt.savefig(figure_output_name+'.loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auroc over time\n",
    "plt.figure()\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "history_auroc = np.array([np.array(h.history['auroc']) for h in history_list])\n",
    "mean_history_auroc = np.mean(history_auroc, axis=0)\n",
    "\n",
    "plt.plot(mean_history_auroc)\n",
    "plt.title('training auROC')\n",
    "plt.ylabel('auroc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "#plt.savefig(figure_output_name+'.auROC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auprc over time\n",
    "plt.figure()\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "history_auprc = np.array([np.array(h.history['auprc']) for h in history_list])\n",
    "mean_history_auprc = np.mean(history_auprc, axis=0)\n",
    "\n",
    "plt.plot(mean_history_auprc)\n",
    "plt.title('training auPRC')\n",
    "plt.ylabel('auprc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "#plt.savefig(figure_output_name+'.auPRC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC in test set\n",
    "ax = plt.figure(figsize=(5, 5))\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "tpr_list = []\n",
    "auroc_list = []\n",
    "for i in range(len(y_test_list)):\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test_list[i], y_pred_list[i])\n",
    "    auroc_list.append(sklearn.metrics.roc_auc_score(y_test_list[i], y_pred_list[i]))\n",
    "    plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "    tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tpr_list.append(tpr)\n",
    "\n",
    "\n",
    "print(len(tpr_list), len(tpr_list[0]), len(tpr_list[1]))\n",
    "tpr_list = np.array(tpr_list)\n",
    "mean_tpr = np.mean(np.array(tpr_list), axis=0)\n",
    "tpr_std = tpr_list.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tpr + 2 * tpr_std, 1)\n",
    "tprs_lower = mean_tpr - 2 * tpr_std\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(base_fpr, mean_tpr, 'b', label='(area = {:.3f})'.format(np.mean(np.array(auroc_list))))\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "with open('./output/03_training_ResNet_cross_validation.DNase.ROC.pickle','wb') as fid:\n",
    "    pickle.dump(ax, fid)\n",
    "#plt.savefig(figure_output_name+'.ROC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRC in test set\n",
    "ax = plt.figure(figsize=(5, 5))\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "base_recall = np.linspace(0, 1, 101)\n",
    "precision_list = []\n",
    "auprc_list = []\n",
    "for i in range(len(y_test_list)):\n",
    "    recall, precision, thresholds = sklearn.metrics.precision_recall_curve(y_test_list[i], y_pred_list[i])\n",
    "    auprc_list.append(sklearn.metrics.average_precision_score(y_test_list[i], y_pred_list[i]))\n",
    "    plt.plot(recall, precision, 'b', alpha=0.15)\n",
    "    precision = np.interp(base_recall, recall, precision)\n",
    "    precision[0] = 1.0\n",
    "    precision_list.append(precision)\n",
    "\n",
    "print(len(precision_list), len(precision_list[0]), len(precision_list[1]))\n",
    "precision_list = np.array(precision_list)\n",
    "mean_precision = np.mean(np.array(precision_list), axis=0)\n",
    "precision_std = precision_list.std(axis=0)\n",
    "\n",
    "precisions_upper = np.minimum(mean_precision + 2 * precision_std, 1)\n",
    "precisions_lower = mean_precision - 2 * precision_std\n",
    "\n",
    "plt.plot([0, 1], [1, 0], 'k--')\n",
    "plt.plot(base_recall, mean_precision, 'b', label='(area = {:.3f})'.format(np.mean(np.array(auprc_list))))\n",
    "plt.fill_between(base_recall, precisions_lower, precisions_upper, color='grey', alpha=0.3)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.title('PRC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "with open('./output/03_training_ResNet_cross_validation.DNase.PRC.pickle','wb') as fid:\n",
    "    pickle.dump(ax, fid)\n",
    "#plt.savefig(figure_output_name+'.PRC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation accuracy: \" + str(np.mean(np.array(accuracy_list))))\n",
    "print(\"validation auROC: \" + str(np.mean(np.array(auroc_list))))\n",
    "print(\"validation auPRC: \" + str(np.mean(np.array(auprc_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
